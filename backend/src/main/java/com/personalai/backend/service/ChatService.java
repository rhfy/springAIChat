package com.personalai.backend.service;

import com.personalai.backend.dto.ChatRequest;
import reactor.core.publisher.Flux;
import reactor.core.publisher.Mono;

/**
 * Service interface for AI chat interactions using Spring AI ChatClient.
 * 
 * This interface defines the contract for chat operations including:
 * - Standard chat completions returning text responses
 * - Structured output mapping to Java objects
 * - Streaming responses for real-time interactions
 * 
 * Implementations should use Spring AI's ChatClient fluent API and integrate
 * with configured advisors for cross-cutting concerns (logging, retry, memory, etc.).
 * 
 * Requirements: 1.1, 5.1, 8.4, 12.1
 */
public interface ChatService {

    /**
     * Process a chat request and return AI response as text.
     * 
     * This method handles:
     * - Message history processing
     * - Conversation memory management
     * - Advisor chain execution (logging, retry, observability)
     * - AI model invocation
     * 
     * @param chatRequest the incoming chat request with message history
     * @return Mono containing the AI assistant's response text
     * @throws IllegalArgumentException if chatRequest is null or invalid
     * @throws RuntimeException if AI model invocation fails after retries
     */
    Mono<String> getChatCompletion(ChatRequest chatRequest);

    /**
     * Process a chat request with structured output mapping.
     * 
     * This method maps the AI response to a Java object of the specified type.
     * Useful for extracting structured data from AI responses (e.g., JSON objects,
     * DTOs with specific fields).
     * 
     * @param <T> the type of the response object
     * @param chatRequest the incoming chat request with message history
     * @param responseType the target class for structured output mapping
     * @return Mono containing the mapped response object
     * @throws IllegalArgumentException if chatRequest or responseType is null
     * @throws RuntimeException if mapping fails or response doesn't match schema
     */
    <T> Mono<T> getChatCompletionStructured(ChatRequest chatRequest, Class<T> responseType);

    /**
     * Process a chat request with streaming response.
     * 
     * This method returns a Flux that emits response chunks progressively as they
     * are generated by the AI model. Useful for real-time user interfaces that
     * display responses as they are being generated.
     * 
     * @param chatRequest the incoming chat request with message history
     * @return Flux emitting response chunks as they are generated
     * @throws IllegalArgumentException if chatRequest is null or invalid
     * @throws RuntimeException if AI model invocation fails
     */
    Flux<String> getChatCompletionStream(ChatRequest chatRequest);
}
